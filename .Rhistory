get_minutes <- function(timestring){
return(substr(timestring, 11, 12))
}
utc_diff <- difference_to_UTC()
utc_diff
hour <- get_hour(timestring)
hour
get_hour(timestring)
as.numeric(get_hour(timestring))
as.numeric(get_hour(timestring)) + utc_diff
as.character(as.numeric(get_hour(timestring)) + utc_diff)
hour_adjusted <- as.character(as.numeric(get_hour(timestring)) + utc_diff)
hour_adjusted
timestring
substr(timestring, 9, 10) <- hour_adjusted
get_date <- function(timestring){
return(substr(timestring, 0, 8))
}
date <- get_date(timestring)
date
get_time <- function(timestring){
return(substr(timestring, 9, 12))
}
date <- str_c(get_year(timestring), get_month(timestring), get_day(timestring), sep = "-")
date
time_adjusted <- str_c(hour_adjusted, get_minutes(timestring), "00", sep = ":")
time_adjusted
paste(date, time_adjusted, sep = " ")
localtime <- function(timestring){
utc_diff <- difference_to_UTC()
hour_adjusted <- as.character(as.numeric(get_hour(timestring)) + utc_diff)
date <- str_c(get_year(timestring), get_month(timestring), get_day(timestring), sep = "-")
time_adjusted <- str_c(hour_adjusted, get_minutes(timestring), "00", sep = ":")
return(paste(date, time_adjusted, sep = " "))
}
# Correct for UTC-time (summer: UTC+2, winter: UTC+1)
time <- as.matrix(badewetter_subset[, "Time"])
time
time[1,]
options(scipen = -999)
time
options(scipen = 999)
time
# Correct for UTC-time (summer: UTC+2, winter: UTC+1)
time <- badewetter_subset[, "Time"]
time
# Correct for UTC-time (summer: UTC+2, winter: UTC+1)
time_adjusted <- localtime(badewetter_subset[1, "Time"])
time_adjusted
time_adjusted <- rep(time_adjusted, dim(badewetter_subset)[1])
time_adjusted
badewetter_subset[, "Time"] <- time_adjusted
badewetter_subset
# This script is for the preprocessing of the measurements of the automated weather stations of the
# Federal Office of Climatology and Meteorology (MeteoSwiss)
# Preprocessing for the swiss beach-weather index (Badewetter-Index Schweiz)
# The application can be found at: https://badewetter-index-schweiz.opendata.iwi.unibe.ch/
# Created by: Christoph von Matt
# Date: 08.07.2019
# Licence: CC-BY-SA
######## General Information ##########
# This script executes 2 preprocessing tasks:
#   1) get current measurements from the automatic weather station dataset of MeteoSwiss
#   2) (If necessary) preparation of MeteoSwiss-Station's metadata
#   3) Join created/existing metadata with stations data
#   4) Calculation of the Badewetter-Index
#
# The script outputs the following files:
#   1) "weather_data_joined.csv"
#   2) if not existing: "weather_metadata.csv"
# libraries
library(tidyverse)
library(data.table)
library(bit64)
# Pathes
# data folder (destination folder)
path <- "data"
# Measurements
measurements_path <- "https://data.geo.admin.ch/ch.meteoschweiz.messwerte-aktuell/VQHA80.csv"
# meta_path <- "data/metadata_wetterstationen.txt"
meta_path <- "https://data.geo.admin.ch/ch.meteoschweiz.messwerte-aktuell/info/VQHA80_de.txt"
# Create directory
dir.create(paste(path, "meteoswiss_data", sep="/"), showWarnings = F)
###################################################################################################
# Section 0: Auxiliary Functions
# gets metadata_starting column
get_start_line <- function(lines){
# colnames
col_names <- c("stn", "Name", "Länge/Breite", "KM-Koordinaten", "Höhe")
# Get all indizes which match
indizes_per_colname <- list()
for (i in 1:length(col_names)){
indizes_per_colname[[i]] <- grep(col_names[i], lines)
}
# Return the indizes which all have in common
return(Reduce(intersect, indizes_per_colname))
}
# Function returns the line where the metadata-table ends
get_end_line <- function(lines, start_line, lines_expected){
# empty lines used to find break after table
empty_lines <- which(lines == "")
# expected end
exp_end <- start_line + lines_expected
# get index of most probable end-line
# gets the first index which is greated/equal to expected end
end_line <- empty_lines[min(which(empty_lines >= exp_end))]
return(end_line - 1)
}
# Prepare Meta-Data such that it can be processed
# subsets lines and cleans empty lines in-between (if there are any)
get_cleaned_subset <- function(lines, start_line, end_line){
# subset data
line_subset <- lines[start_line:end_line]
# check if there are still empty lines
if(length(which(line_subset == "")) != 0){
empty_lines = which(line_subset == "")
# filter empty lines out
line_subset[-empty_lines]
}
return(line_subset)
}
# read in temporary meta-data
read_meta_correctly <- function(path){
#define fix-width lengths
#define the length of each fixed-width column
lengths <- c(
str_length("stn                                       "),
str_length("Name                         "),
str_length("Länge/Breite                              "),
str_length("KM-Koordinaten                            "),
str_length("Höhe")
)
# Colnames within dataset (hard-coded = must be known in advance!)
col_names <- c("Station", "Name", "Länge/Breite", "Koordinaten", "Höhe")
# read-in metadata
data <- read_fwf(path, col_positions = fwf_widths(lengths, col_names = col_names),
trim_ws = T, skip = 2, locale = locale(encoding = "ISO-8859-1"))
return(data)
}
# Function which checks for summertime / wintertime correction
# solutions found under stackoverflow
# https://stackoverflow.com/questions/8879864/how-to-find-summertime-adjustment-for-a-given-date-and-timezone-in-r
# TODO: handling times when clocks are set to winter / summer-times? Problem at 00:00 / 02:00 ?
difference_to_UTC <- function(){
# timezone + current time
tz = Sys.timezone()
current_time = Sys.time()
# UTC-time
utc <- as.POSIXct(format(current_time,  tz = 'UTC'),  tz = tz)
return(round(as.numeric(current_time - utc)))
}
# functions to split timestring
get_year <-  function(timestring){
return(substr(timestring, 0, 4))
}
get_month <- function(timestring){
return(substr(timestring, 5, 6))
}
get_day <- function(timestring){
return(substr(timestring, 7, 8))
}
get_hour <- function(timestring){
return(substr(timestring, 9, 10))
}
get_minutes <- function(timestring){
return(substr(timestring, 11, 12))
}
get_date <- function(timestring){
return(substr(timestring, 0, 8))
}
get_time <- function(timestring){
return(substr(timestring, 9, 12))
}
# Function to adjust timestring for UTC
localtime <- function(timestring){
#get UTC difference
utc_diff <- difference_to_UTC()
# adjust hour for difference
hour_adjusted <- as.character(as.numeric(get_hour(timestring)) + utc_diff)
# Prepare date + adjusted time for POSIXct-format
date <- str_c(get_year(timestring), get_month(timestring), get_day(timestring), sep = "-")
time_adjusted <- str_c(hour_adjusted, get_minutes(timestring), "00", sep = ":")
return(paste(date, time_adjusted, sep = " "))
}
###################################################################################################
# Section 1: Fetch newest measurements of the automated weather stations of MeteoSwiss + prepare for join
# 1.1 Read and Process newest Meteo-Station data
# TODO: correct for UTC-time! (also dependent on current date!) e.g. use today() then determine whether summer or winter
# time to use
(ms_data <- as.data.frame(fread(measurements_path, na.strings = "-")))
cols_orig <- colnames(ms_data)
cols_new <- c("Station", "Time", "Temperatur (°C)", "Niederschlag (mm)", "Sonnenschein (min)",
"Globalstrahlung (W/m^2)", "Luftfeuchtigkeit (%)", "Taupunkt (°C)", "Windrichtung (°)",
"Windgeschwindigkeit (km/h)", "Böenspitze (km/h)", "Luftdruck auf Stationshöhe (QFE, hPa)",
"Luftdruck auf Meeresniveau (QFF, hPa)", "Luftdruck reduziert auf Meereshöhe mit Standard-Atmosphäre (QNH, hPa)",
"Geopotential 850hPa (gpm)", "Geopotential 700hPa (gpm)", "Windrichtung vekt (°)",
"Windgeschw. Turm (km/h)", "Böenspitze Turm (km/h)", "Lufttemperatur Instr 1 (°C)",
"RH Turm (%)", "Taupunkt Turm (°C)")
# Define shortcut variable names through new Column names
colnames(ms_data) <- cols_new
# Subset required for Badewetter-Index
subset_cols <- cols_new[c(1:7, 10)]
badewetter_subset <- ms_data[, subset_cols]
# Correct for UTC-time (summer: UTC+2, winter: UTC+1)
time_adjusted <- localtime(badewetter_subset[1, "Time"])
time_adjusted <- rep(time_adjusted, dim(badewetter_subset)[1])
badewetter_subset[, "Time"] <- time_adjusted
rm("cols_new", "cols_orig")
###################################################################################################
# Section 2: Process Metadata
# FETCH METADATA + PROCESS (if necessary)
# Check if file already exists
if(!file.exists(paste(path, "meteoswiss_data/weather_metadata.csv", sep = "/"))){
print("Metadata-File fetching and processing initialised...")
lines <- readLines(meta_path)
# Get required indizes
start_line <- get_start_line(lines)
expected_lines <- dim(ms_data)[1]
end_line <- get_end_line(lines, start_line, expected_lines)
# Get cleaned subset of lines
lines <- get_cleaned_subset(lines, start_line, end_line)
# Temporary file-storage
write(lines, paste(path, "meteoswiss_data/temporary_meta.txt", sep = "/"))
rm("lines", "start_line", "expected_lines", "end_line")
# Read-in temporary-file
meta_data <- read_meta_correctly(paste(path, "meteoswiss_data/temporary_meta.txt", sep = "/"))
# Tidy data
meta_data <- meta_data %>% select(Station, Name, Koordinaten, Höhe) %>%
mutate(Longitude = as.numeric(str_split(Koordinaten, "/")[[1]][1]),
Latitude = as.numeric(str_split(Koordinaten, "/")[[1]][2])) %>%
select(-Koordinaten)
# write processed meta-data
write.csv(meta_data, paste(path, "meteoswiss_data/weather_metadata.csv", sep = "/"), row.names = F, fileEncoding = "ISO-8859-1")
# remove temporary file
file.remove(paste(path, "meteoswiss_data/temporary_meta.txt", sep = "/"))
rm("lon_lats")
}else{
meta_data <- read_csv(paste(path, "meteoswiss_data/weather_metadata.csv", sep = "/"), locale = locale(encoding = "ISO-8859-1"))
}
###################################################################################################
# Section 3: Join Measurement-Data + Metadata
# Join data
joined <- right_join(meta_data, badewetter_subset, by="Station")
# convert to data-frame (columns not tibble compatible)
joined <- as.data.frame(joined)
# Write final table as CSV
write.csv(joined, paste(path, "meteoswiss_data/weatherdata_joined.csv", sep = "/"), row.names = F, na = "-", fileEncoding = "ISO-8859-1")
rm(list=ls())
# This script is for the preprocessing of river + lake measurements from the Federal Office of Environment
# Preprocessing for the swiss beach-weather index (Badewetter-Index Schweiz)
# The application can be found at: https://badewetter-index-schweiz.opendata.iwi.unibe.ch/
# Created by: Christoph von Matt
# Date: 08.07.2019
# Licence: CC-BY-SA
######## General Information ##########
# This script executes 2 preprocessing tasks:
#   1) Query of current river + lake measurement data (JSON-file) from the Federal Office of Environment (FOEN)
#   2) For each feature: Scraping the following parameters:
#     - time, last measured temperature, mean temperature (24h), max temperature (24h), height of station, catchment-size
#
# The script outputs the following files:
#   1) "flussdaten_updated.json"
# libraries
library(httr)
library(XML)
library(rjson)
library(stringr)
###################################################################################################
# Section 0: Auxiliary Functions
extract_webURL <- function(attribute_containing_URL){
attribute2HTML <- htmlParse(attribute_containing_URL)
# Returns the href-attribute of the given string
return(xpathApply(attribute2HTML, "//a/@href")[[1]][1])
}
# Reads the BAFU-HTML-table of measurements of a station site
# Returns a table
read_station_HTMLtable <- function(url){
# Opening web-page
station_site <- GET(url)
station_site <- htmlParse(station_site, encoding = "utf-8")
station_site <- xmlRoot(station_site)
# Return table
return(readHTMLTable(station_site, which = 1, header = F))
}
# Scrapes current temperature data from river-station
scrape_time_temperature <- function(data_table){
column <- grep("Temper+", unlist(data_table[1,]))
# Time
time = str_extract(data_table[1,column], "[0-9]+:[0-9]+")
# Temperatures
temperatures <- as.numeric(as.vector(data_table[2:4, column]))
# Returns Time,  Letzer Messwert, Mittelwert über letzte 24h, Maximum letzte 24h
return(list(time, temperatures))
}
# Extracts values from string + turns it into numeric
get_attributes_as_numeric <- function(string_with_value){
return(as.numeric(strsplit(string_with_value, " ")[[1]][1]))
}
# Scrapes meta-data from riverstation
scrape_metadata <- function(data_table){
row_height <- grep("Stationshöhe", data_table[,1])
row_catchment <- grep("Grösse des Einzugsgebietes", data_table[,1])
# output
out <- rep(NA, 2)
# Returns Stationshöhe, Grösse des Einzugsgebiets
values <- as.vector(data_table[c(row_height, row_catchment), 2])
for (i in 1:2){
out[i] <-get_attributes_as_numeric(values[i])
}
return(out)
}
###################################################################################################
# Section 1: Fetching newest river- data
# TODO: include river-temperatures in the interpolation of the badewetter-index too?
# -->or just use the actual temperatures as additional conditon which the user could specify on its own
# --> such that then the bade-index is alterd such that only regions are displayed where also the river/lake temperatures
# are adequately for bathing
# TODO: create an executable function out of the whole script
# TODO: if running on Linux: coordination with BASH-Script preferable
# Outfile
path <- "data"
# url
file <- "http://data.geo.admin.ch/ch.bafu.hydroweb-messstationen_temperatur/ch.bafu.hydroweb-messstationen_temperatur_de.json"
# read-in JSON-format
rivers_json <- fromJSON(file=file, simplify = T) # TODO: really necessary to simplify?
river_features <- rivers_json$features
# Updated feature-list
updated_features <- list()
# Add Temperature and Metadata-Information for every feature in data-set
# Loop over all features
print("Feature data fetching initialised...")
print(paste("Total features being processed:", length(river_features)))
for (i in 1:length(river_features)){
# get current feature
feature <- river_features[[i]]
# get current properties
ft_props <- feature$properties
# Get Web-URL
ft_url <- extract_webURL(ft_props$description)
# Get Temperature Values: 1 = current, 2 = mean 24h, 3 = max 24h
time_temperatures <- scrape_time_temperature(read_station_HTMLtable(ft_url))
# Get Metadata: 1 = Stationshöhe (m.ü.M.), 2 = Einzugsgebiet (km^2)
stat_meta <- scrape_metadata(read_station_HTMLtable(ft_url))
# Add the additional elements to the feature properties
# time
ft_props$time <- time_temperatures[[1]]
# Current Temperature
ft_props$current <- time_temperatures[[2]][1]
# Mittlere Temperature 24h
ft_props$mittlereT24h <- time_temperatures[[2]][2]
# Maximale Temperatur 24h
ft_props$maxT24h <- time_temperatures[[2]][3]
# Stationshöhe
ft_props$statHeight <- stat_meta[1]
# Einzugsgebiet
ft_props$catchment <- stat_meta[2]
# Update features
feature$properties <- ft_props
# add updated feature to new feature-list
updated_features[[i]] <- feature
}
# replace features with updated ones
rivers_json$features <- updated_features
# Convert update list to JSON
out_json <- toJSON(rivers_json)
# TODO: could also be other data format
# Create directory
dir.create(paste(path, "riverdata", sep="/"), showWarnings = F)
# write Updated JSON
write(out_json, file=paste(path, "riverdata/flussdaten_updated.json", sep = "/"))
rm(list=ls())
# This script calculates the badewetter-index using measurement data of the automated weather stations of the
# Federal Office of Climatology and Meteorology (MeteoSwiss)
# Calculation of the Badewetter-Index Schweiz (swiss beach-weather index)
# The application can be found at: https://badewetter-index-schweiz.opendata.iwi.unibe.ch/
# Created by: Christoph von Matt
# Date: 08.07.2019
# Licence: CC-BY-SA
######## General Information ##########
# This script executes 1 tasks:
#   1) Calculation of the Badewetter-Index Schweiz (Swiss beach-weather index)
#
# The script outputs the following files:
#   1) "badewetter_index.csv"
# libraries / functions
source("index_auxiliary.R")
###################################################################################################
# Section 1: Calculation of the Badewetter-Index
# SETTINGS
# set-up values
path = "data"
# Setting Max-values + weights for calculation
# Temperature (degC)
temp_max <-  45
temp_wgt <-  0.4
# Precipitation (mm)
prec_wgt <- 0.2
# Sunshine Durance (min)
sun_max <- 10
sun_wgt <- 0.05
# Global Radiation (W/m^2)
glob_max <- 1000
glob_wgt <- 0.05
# RH / Relative Humidity (%)
feu_wgt <- 0.15
# Wind (km/h)
wind_max <- 25
wind_wgt <- 0.15
# Read-in data
# TODO: Correct time to UTC+2 (summer) / UTC+1 (winter)
joined_data <- read.csv(paste(path, "meteoswiss_data/weatherdata_joined.csv", sep = "/"), na.strings = "-", encoding = "ISO-8859-1", header = T,
check.names = T)
# get dimensions r-rows, c-cols
dims <- dim(joined_data)
r <- dims[1]
c <- dims[2]
# Badewetter-Index Calculation
index <- rep(NA, r)
col_names <- colnames(joined_data)
# BADEWETTER-INDEX CALCULATION
for(i in 1:r){
temp <- as.numeric(joined_data[i,grep("Temp+", col_names)])
print(temp)
prec <- as.numeric(joined_data[i,grep("Nieder+", col_names)])
sun <- as.numeric(joined_data[i,grep("Sonnen+", col_names)])
glob <- as.numeric(joined_data[i,grep("Global+", col_names)])
feu <- as.numeric(joined_data[i,grep("Luftfeu+", col_names)])
wind <- as.numeric(joined_data[i,grep("Windgesch+", col_names)])
# Index is only calculated if two most important variables (temperature + precipitation) are available
if(!(is.na(temp) || is.na(prec))){
#index[i] <- 0.4*temp + 0.2*prec + 0.05*sun + 0.05*glob + 0.15*feu + 0.15*wind
index[i] <- temp_cont(temp, temp_wgt, temp_max) + prec_cont(prec, prec_wgt) + sun_cont(sun, sun_wgt, sun_max) +
glob_cont(glob, glob_wgt, glob_max) + feu_cont(feu, feu_wgt) + wind_cont(wind, wind_wgt, wind_max)
}
}
# Possible Index-Range with given specifications for max-variables + weights
# TODO: could / should be standardized such that values are always in the range 0-100
#maxindex
maxi <- temp_cont(temp_max, temp_wgt, temp_max) + prec_cont(0, prec_wgt) + sun_cont(sun_max, sun_wgt, sun_max) +
glob_cont(glob_max, glob_wgt, glob_max) + feu_cont(90, feu_wgt) + wind_cont(0, wind_wgt, wind_max)
(maxi*100)
#minindex
mini <- temp_cont(-10, temp_wgt, temp_max) + prec_cont(1, prec_wgt) + sun_cont(0, sun_wgt, sun_max) +
glob_cont(0, glob_wgt, glob_max) + feu_cont(0, feu_wgt) + wind_cont(wind_max, wind_wgt, wind_max)
(mini*100)
# Standardization
index <- 1/maxi*index
# Scale Index up + add to data
index <- as.integer(index*100)
joined_data[,c+1] <- index
colnames(joined_data)[c+1] <- "Index"
# update colnames
col_names <- colnames(joined_data)
###################################################################################################
# Section 2: WRITING END-PRODUCT FILES FOR USE IN QGIS
# Create directory
dir.create(paste(path, "index", sep="/"), showWarnings = F)
#Write csv
write.csv(joined_data, paste(path, "index/badeindex.csv", sep = "/"), row.names = F, na = "-", fileEncoding = "ISO-8859-1")
# Write csvt-file with type of each column (required for reading table in QGIS)
if(!file.exists(paste(path, "index/badeindex.csvt", sep = "/"))){
col_type <- c("\"String\", \"String\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\", \"Real\"")
write(col_type, paste(path, "index/badeindex.csvt", sep = "/"), ncolumns = length(col_names))
}
rm(list=ls())
# Print list
print_list <- function(vector_of_strings){
for(i in 1:length(vector_of_strings)){
print(paste(i, ": " , vector_of_strings[i], sep=""))
}
}
# Returns index of a column
get_index <- function(name, colnames=col_names){
if(length(grep(name, col_names)) > 0){
return(grep(name, col_names))
}
return(NA)
}
# Returns indizes of search columns
get_indizes <- function(names, colnames=col_names){
if(length(names) == 1){
return(get_index(names))
}else{
ind_out <- rep(NA, length(names))
for(i in 1:length(names)){
ind_out[i] <- get_index(names[i])
}
not_found <- which(is.na(ind_out))
if(length(not_found) >= 1){
print("Only returning found columns!")
print("The following columns were not found:")
print_list(names[not_found])
}
return(ind_out[which(!is.na(ind_out))])
}
}
###################################################################################################
# Section 1: SET-UP DATA
path <- "data"
# Read generated badewetter-index file
badeindex_data <- read.csv(paste(path, "index/badeindex.csv", sep = "/"), header = T, na.strings = "-")
col_names <- colnames(badeindex_data)
# subset columns for badewetter-index interpolation
indizes <- get_indizes(c("Latitude", "Longitude", "Index"))
index_subset <- badeindex_data[,indizes]
# Convert file to GeoJSON
lat_lon <- get_indizes(c("Latitude", "Longitude"))
toGeoJSON(badeindex_data, "badewetter", path, lat.lon = lat_lon, overwrite = T)
#libraries
library(rjson)
library(leafletR)
toGeoJSON(badeindex_data, "badewetter", path, lat.lon = lat_lon, overwrite = T)
